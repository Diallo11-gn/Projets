{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliothèques et importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. Charger les données\n",
    "PathDicom = \"C:\\\\Users\\\\mamad\\\\Downloads\\\\dicom-images-train\"\n",
    "CSVPath = \"C:\\\\Users\\\\mamad\\\\Downloads\\\\trainSet-rle.csv\"\n",
    "df = pd.read_csv(CSVPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyer la colonne EncodedPixels\n",
    "df[\"EncodedPixels\"] = df[\"EncodedPixels\"].str.strip()\n",
    "\n",
    "# Définir la cible : 0 (absence) ou 1 (présence de pneumothorax)\n",
    "df[\"Pneumothorax\"] = df[\"EncodedPixels\"].apply(lambda x: 0 if x == \"-1\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prétraitement des données\n",
    "def load_image(image_path):\n",
    "    dicom = pydicom.dcmread(image_path)\n",
    "    img = dicom.pixel_array\n",
    "    # Vérification et normalisation (si nécessaire)\n",
    "    img = img - np.min(img)  \n",
    "    img = img / np.max(img)  \n",
    "    return img\n",
    "\n",
    "def preprocess_images(image_paths, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = load_image(path)\n",
    "        img = tf.image.resize(img[..., np.newaxis], target_size)  \n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Associer les chemins des fichiers DICOM au DataFrame\n",
    "df[\"Path\"] = df[\"ImageId\"].apply(lambda x: os.path.join(PathDicom, f\"{x}.dcm\"))\n",
    "\n",
    "# Séparer les données en ensembles train/validation avec stratification\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"Pneumothorax\"])\n",
    "\n",
    "# Charger les images\n",
    "train_images = preprocess_images(train_df[\"Path\"].values)\n",
    "val_images = preprocess_images(val_df[\"Path\"].values)\n",
    "\n",
    "# Extraire les labels\n",
    "train_labels = train_df[\"Pneumothorax\"].values\n",
    "val_labels = val_df[\"Pneumothorax\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction et entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mamad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 383ms/step - accuracy: 0.7056 - loss: 0.6478 - val_accuracy: 0.7154 - val_loss: 0.5768\n",
      "Epoch 2/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 381ms/step - accuracy: 0.7153 - loss: 0.5827 - val_accuracy: 0.7149 - val_loss: 0.5862\n",
      "Epoch 3/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 394ms/step - accuracy: 0.7222 - loss: 0.5635 - val_accuracy: 0.7163 - val_loss: 0.5825\n",
      "Epoch 4/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 393ms/step - accuracy: 0.7265 - loss: 0.5519 - val_accuracy: 0.7249 - val_loss: 0.5691\n",
      "Epoch 5/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 383ms/step - accuracy: 0.7295 - loss: 0.5247 - val_accuracy: 0.7235 - val_loss: 0.5653\n",
      "Epoch 6/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 374ms/step - accuracy: 0.7467 - loss: 0.4918 - val_accuracy: 0.7425 - val_loss: 0.5409\n",
      "Epoch 7/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 386ms/step - accuracy: 0.7878 - loss: 0.4323 - val_accuracy: 0.7463 - val_loss: 0.5600\n",
      "Epoch 8/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 379ms/step - accuracy: 0.8233 - loss: 0.3759 - val_accuracy: 0.7630 - val_loss: 0.5623\n",
      "Epoch 9/10\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 382ms/step - accuracy: 0.8606 - loss: 0.3204 - val_accuracy: 0.7520 - val_loss: 0.5895\n"
     ]
    }
   ],
   "source": [
    "# 2. Construire le modèle de classification\n",
    "def build_classification_model(input_shape=(256, 256, 1)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),  \n",
    "        layers.Dense(1, activation='sigmoid')  \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_classification_model()\n",
    "\n",
    "# 3. Callbacks pour sauvegarder le meilleur modèle\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, monitor=\"val_loss\") \n",
    "]\n",
    "\n",
    "# 4. Entraîner le modèle\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 137ms/step\n"
     ]
    }
   ],
   "source": [
    "# Charger le meilleur modèle sauvegardé\n",
    "best_model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "\n",
    "# Prédire sur l'ensemble de validation\n",
    "val_predictions = (best_model.predict(val_images) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Sauvegarder les résultats\n",
    "val_results = pd.DataFrame({\n",
    "    \"ImageId\": val_df[\"ImageId\"].values,\n",
    "    \"Pneumothorax\": val_predictions\n",
    "})\n",
    "val_results.to_csv(\"classification_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie 2 : Les masques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement et normalisation d'une image DICOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    dicom = pydicom.dcmread(image_path)\n",
    "    img = dicom.pixel_array\n",
    "    img = img - np.min(img)  \n",
    "    img = img / np.max(img)  \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Décodage du masque RLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(1024, 1024)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prétraitement des images et masques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_and_masks(df, target_size=(256, 256)):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Charger et redimensionner l'image\n",
    "        img = load_image(row[\"Path\"])\n",
    "        img = tf.image.resize(img[..., np.newaxis], target_size)\n",
    "        images.append(img)\n",
    "\n",
    "        # Charger et redimensionner le masque\n",
    "        if row[\"EncodedPixels\"] == \"-1\":\n",
    "            mask = np.zeros((1024, 1024))  \n",
    "        else:\n",
    "            mask = rle_decode(row[\"EncodedPixels\"])\n",
    "        mask = tf.image.resize(mask[..., np.newaxis], target_size)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Charger les chemins des fichiers DICOM\n",
    "df[\"Path\"] = df[\"ImageId\"].apply(lambda x: os.path.join(PathDicom, f\"{x}.dcm\"))\n",
    "\n",
    "# Séparer les données en train/validation\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=(df[\"EncodedPixels\"] != \"-1\"))\n",
    "\n",
    "# Prétraiter les images et masques\n",
    "train_images, train_masks = preprocess_images_and_masks(train_df)\n",
    "val_images, val_masks = preprocess_images_and_masks(val_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction du Modèle\n",
    "#### Définition d'un modèle U-Net pour la segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_model(input_shape=(256, 256, 1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = layers.UpSampling2D((2, 2))(c3)\n",
    "    u1 = layers.Conv2D(128, (2, 2), activation='relu', padding='same')(u1)\n",
    "    u1 = layers.Concatenate()([u1, c2])\n",
    "\n",
    "    u2 = layers.UpSampling2D((2, 2))(u1)\n",
    "    u2 = layers.Conv2D(64, (2, 2), activation='relu', padding='same')(u2)\n",
    "    u2 = layers.Concatenate()([u2, c1])\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(u2)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', dice_coefficient])\n",
    "    return model\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred))\n",
    "\n",
    "# Instancier le modèle\n",
    "model = build_unet_model()\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"best_segmentation_model.keras\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, monitor=\"val_loss\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_images, train_masks,\n",
    "    validation_data=(val_images, val_masks),\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédictions et Encodage des Masques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\"best_segmentation_model.keras\", custom_objects={\"dice_coefficient\": dice_coefficient})\n",
    "\n",
    "val_predictions = best_model.predict(val_images)\n",
    "val_predictions = (val_predictions > 0.5).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encodage RLE des masques prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "val_df[\"PredictedMask\"] = [rle_encode(mask) for mask in val_predictions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = val_df[[\"ImageId\", \"EncodedPixels\", \"PredictedMask\"]]\n",
    "val_results.to_csv(\"segmentation_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
